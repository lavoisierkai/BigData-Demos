# AWS Terraform Modules

Infrastructure as Code for AWS data platform components using Terraform.

## S3 Data Lake Module Architecture

### Infrastructure Overview

```mermaid
graph TB
    subgraph "ğŸ—ï¸ Terraform Module Structure"
        TM1[ğŸ“„ main.tf<br/>S3 Resources]
        TM2[ğŸ“‹ variables.tf<br/>Input Variables]
        TM3[ğŸ“¤ outputs.tf<br/>Resource Outputs]
    end
    
    subgraph "ğŸª£ S3 Bucket Configuration"
        S3M[ğŸ—ƒï¸ Main Bucket<br/>Data Lake Storage]
        S3L[ğŸ“‹ Logging Bucket<br/>Access Logs]
        S3V[ğŸ”„ Versioning<br/>Object History]
        S3E[ğŸ” Encryption<br/>S3/KMS Managed]
    end
    
    subgraph "ğŸ—‚ï¸ Data Lake Structure"
        subgraph "ğŸ¥‰ Bronze Layer"
            B1[ğŸ“¥ raw-data/<br/>JSON, CSV, Avro]
            B2[ğŸ”„ staging/<br/>Incremental Loads]
        end
        
        subgraph "ğŸ¥ˆ Silver Layer"
            S1[âœ… cleaned-data/<br/>Validated Parquet]
            S2[ğŸ”§ validated-data/<br/>Business Rules]
        end
        
        subgraph "ğŸ¥‡ Gold Layer"
            G1[ğŸ“Š analytics/<br/>Star Schema]
            G2[ğŸ“ˆ aggregated/<br/>Pre-computed KPIs]
        end
        
        subgraph "ğŸ—„ï¸ Support Folders"
            SP1[ğŸ“¦ archive/<br/>Historical Data]
            SP2[ğŸ“‹ logs/<br/>Application Logs]
            SP3[â³ temp/<br/>Processing Cache]
        end
    end
    
    subgraph "ğŸ”§ Lifecycle Management"
        LC1[ğŸ“… Transition Rules<br/>IA â†’ Glacier â†’ Deep Archive]
        LC2[ğŸ—‘ï¸ Expiration Rules<br/>Temp Data Cleanup]
        LC3[ğŸ”„ Version Management<br/>Non-current Versions]
    end
    
    subgraph "ğŸ“Š Monitoring & Alerts"
        CW1[ğŸ“ˆ CloudWatch Metrics<br/>Bucket Size, Requests]
        CW2[ğŸš¨ Alarms<br/>Size Thresholds]
        CW3[ğŸ“‹ Logs<br/>Access Patterns]
    end
    
    subgraph "ğŸ”” Event Notifications"
        EN1[âš¡ S3 Events<br/>Object Created/Deleted]
        EN2[ğŸ“¨ SNS Topics<br/>Notifications]
        EN3[ğŸ“¬ SQS Queues<br/>Processing Triggers]
    end

    TM1 --> S3M
    TM1 --> S3L
    TM1 --> S3V
    TM1 --> S3E
    
    S3M --> B1
    S3M --> B2
    S3M --> S1
    S3M --> S2
    S3M --> G1
    S3M --> G2
    S3M --> SP1
    S3M --> SP2
    S3M --> SP3
    
    S3M --> LC1
    S3M --> LC2
    S3M --> LC3
    
    S3M --> CW1
    CW1 --> CW2
    S3L --> CW3
    
    S3M --> EN1
    EN1 --> EN2
    EN1 --> EN3

    classDef terraform fill:#7B42BC,stroke:#fff,stroke-width:2px,color:#fff
    classDef s3 fill:#ff9900,stroke:#232f3e,stroke-width:2px,color:#fff
    classDef bronze fill:#cd7f32,stroke:#000,stroke-width:2px,color:#fff
    classDef silver fill:#c0c0c0,stroke:#000,stroke-width:2px,color:#000
    classDef gold fill:#ffd700,stroke:#000,stroke-width:2px,color:#000
    classDef support fill:#e0e0e0,stroke:#000,stroke-width:2px,color:#000
    classDef management fill:#4caf50,stroke:#fff,stroke-width:2px,color:#fff
    classDef monitoring fill:#2196f3,stroke:#fff,stroke-width:2px,color:#fff
    classDef events fill:#ff5722,stroke:#fff,stroke-width:2px,color:#fff
    
    class TM1,TM2,TM3 terraform
    class S3M,S3L,S3V,S3E s3
    class B1,B2 bronze
    class S1,S2 silver
    class G1,G2 gold
    class SP1,SP2,SP3 support
    class LC1,LC2,LC3 management
    class CW1,CW2,CW3 monitoring
    class EN1,EN2,EN3 events
```

### Data Lake Folder Structure

```
ğŸª£ s3://your-data-lake-bucket/
â”œâ”€â”€ ğŸ¥‰ bronze/                          # Raw data ingestion
â”‚   â”œâ”€â”€ raw-data/
â”‚   â”‚   â”œâ”€â”€ orders/                     # E-commerce orders
â”‚   â”‚   â”œâ”€â”€ customers/                  # Customer master data
â”‚   â”‚   â”œâ”€â”€ products/                   # Product catalog
â”‚   â”‚   â””â”€â”€ events/                     # Application events
â”‚   â””â”€â”€ staging/
â”‚       â”œâ”€â”€ incremental/                # CDC staging area
â”‚       â””â”€â”€ batch/                      # Batch load staging
â”‚
â”œâ”€â”€ ğŸ¥ˆ silver/                          # Refined & validated
â”‚   â”œâ”€â”€ cleaned-data/
â”‚   â”‚   â”œâ”€â”€ orders/                     # Validated orders
â”‚   â”‚   â”œâ”€â”€ customers/                  # Enriched customers
â”‚   â”‚   â””â”€â”€ products/                   # Standardized products
â”‚   â””â”€â”€ validated-data/
â”‚       â”œâ”€â”€ customer-360/               # Unified customer view
â”‚       â””â”€â”€ product-catalog/            # Master product data
â”‚
â”œâ”€â”€ ğŸ¥‡ gold/                            # Business-ready analytics
â”‚   â”œâ”€â”€ analytics/
â”‚   â”‚   â”œâ”€â”€ sales-reports/              # Sales analytics
â”‚   â”‚   â”œâ”€â”€ customer-segments/          # Customer analysis
â”‚   â”‚   â””â”€â”€ product-performance/        # Product metrics
â”‚   â”œâ”€â”€ aggregated/
â”‚   â”‚   â”œâ”€â”€ monthly-kpis/               # Business KPIs
â”‚   â”‚   â””â”€â”€ daily-metrics/              # Operational metrics
â”‚   â””â”€â”€ ml-features/
â”‚       â”œâ”€â”€ customer-features/          # ML feature store
â”‚       â””â”€â”€ recommendation-features/    # Recommendation data
â”‚
â”œâ”€â”€ ğŸ“¦ archive/                         # Long-term storage
â”‚   â”œâ”€â”€ backup/
â”‚   â”‚   â”œâ”€â”€ daily/                      # Daily backups
â”‚   â”‚   â””â”€â”€ monthly/                    # Monthly snapshots
â”‚   â””â”€â”€ regulatory/
â”‚       â””â”€â”€ compliance-data/            # Regulatory archives
â”‚
â”œâ”€â”€ ğŸ“‹ logs/                            # Application & audit logs
â”‚   â”œâ”€â”€ application/
â”‚   â”‚   â”œâ”€â”€ spark/                      # Spark job logs
â”‚   â”‚   â”œâ”€â”€ glue/                       # Glue crawler logs
â”‚   â”‚   â””â”€â”€ emr/                        # EMR cluster logs
â”‚   â”œâ”€â”€ audit/
â”‚   â”‚   â”œâ”€â”€ access/                     # Data access logs
â”‚   â”‚   â””â”€â”€ lineage/                    # Data lineage tracking
â”‚   â””â”€â”€ security/
â”‚       â””â”€â”€ vpc-flow/                   # VPC flow logs
â”‚
â””â”€â”€ â³ temp/                            # Temporary processing
    â”œâ”€â”€ processing/
    â”‚   â”œâ”€â”€ etl/                        # ETL intermediate files
    â”‚   â””â”€â”€ ml-training/                # ML training cache
    â””â”€â”€ cache/
        â””â”€â”€ query-results/              # Query result cache
```

### Module Usage Examples

**Basic Data Lake Setup:**
```hcl
module "data_lake_s3" {
  source = "./modules/s3"
  
  bucket_name    = "my-data-lake"
  environment    = "dev"
  versioning_enabled = true
  
  create_data_lake_structure = true
  data_lake_folders = [
    "bronze/raw-data/orders",
    "silver/cleaned-data/orders",
    "gold/analytics/sales-reports"
  ]
  
  tags = {
    Project = "DataLake"
    Owner   = "DataEngineering"
  }
}
```

**Production Configuration with Enhanced Security:**
```hcl
module "production_data_lake" {
  source = "./modules/s3"
  
  bucket_name           = "company-prod-datalake"
  environment          = "prod"
  enable_random_suffix = false
  force_destroy        = false
  
  # Security Configuration
  versioning_enabled    = true
  enable_kms_encryption = true
  block_public_access   = true
  
  # Comprehensive folder structure
  create_data_lake_structure = true
  data_lake_folders = [
    # Bronze layer
    "bronze/raw-data/transactional/orders",
    "bronze/raw-data/master-data/customers",
    "bronze/staging/real-time",
    
    # Silver layer  
    "silver/cleaned-data/orders",
    "silver/validated-data/customer-360",
    
    # Gold layer
    "gold/analytics/sales-reports/daily",
    "gold/ml-features/customer-features",
    
    # Support folders
    "archive/backup/monthly",
    "logs/application/spark",
    "temp/processing/etl"
  ]
  
  # Lifecycle management
  lifecycle_rules = [
    {
      id      = "production_lifecycle"
      enabled = true
      filter = {
        prefix = ""
      }
      transitions = [
        {
          days          = 30
          storage_class = "STANDARD_IA"
        },
        {
          days          = 180
          storage_class = "GLACIER"
        },
        {
          days          = 1095  # 3 years
          storage_class = "DEEP_ARCHIVE"
        }
      ]
    }
  ]
  
  tags = {
    Environment = "Production"
    Project     = "Enterprise-DataLake"
    Owner       = "DataEngineering-Team"
    Compliance  = "SOX-GDPR"
  }
}
```

## Examples

### Data Lake Example
Basic data lake implementation with standard medallion architecture.

**Deploy:**
```bash
cd examples/data-lake
terraform init
terraform plan -var-file="terraform.tfvars"
terraform apply
```

### Production Example
Production-ready configuration with enhanced security and compliance features.

**Configuration:**
- Enhanced security with private endpoints
- Comprehensive lifecycle rules
- Event notifications for data processing
- Compliance-ready retention policies

## Directory Structure

```
aws/
â”œâ”€â”€ modules/
â”‚   â””â”€â”€ s3/                 # S3 module for data lake
â”‚       â”œâ”€â”€ main.tf         # Main resources
â”‚       â”œâ”€â”€ variables.tf    # Input variables
â”‚       â””â”€â”€ outputs.tf      # Output values
â””â”€â”€ examples/
    â”œâ”€â”€ data-lake/          # Basic data lake example
    â””â”€â”€ production/         # Production configuration
```

## Key Features

### Security
- Server-side encryption (S3-managed or KMS)
- Public access blocking
- Bucket versioning
- Access logging

### Cost Optimization
- Intelligent lifecycle transitions
- Storage class optimization
- Temporary data cleanup
- Monitoring and alerting

### Data Lake Architecture
- Medallion architecture (Bronze/Silver/Gold)
- Standardized folder structure
- Event-driven processing
- Audit and compliance logging

## Variables

### Required
- `bucket_name` - Base name for S3 bucket
- `environment` - Environment (dev/staging/prod)

### Optional
- `versioning_enabled` - Enable bucket versioning (default: true)
- `create_data_lake_structure` - Create standard folders (default: true)
- `lifecycle_rules` - Custom lifecycle rules
- `tags` - Resource tags

## Outputs

### Bucket Information
- `bucket_id` - S3 bucket name
- `bucket_arn` - S3 bucket ARN
- `bucket_region` - AWS region

### Data Lake Paths
- `data_lake_paths` - Standard tier paths
- `integration_endpoints` - Service integration URLs
- `monitoring_info` - CloudWatch configuration